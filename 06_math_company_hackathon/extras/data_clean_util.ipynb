{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data cleaning util for cipla DS challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://analyticsindiamag.com/5-ways-handle-missing-values-machine-learning-datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Working with missing values detailed](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct me if I am wrong on my understanding?\n",
    "1) We use mean to handle missing values when particular column is normally distributed. We can use median/mode if we have outliers in that partilcar data column {although, we don't prefer outliers}\n",
    "\n",
    "2) As a result of linear regression used above, we get predicted age (y_hat) which is being replaced where there is missing values in the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClean:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(path):\n",
    "        \"\"\"\n",
    "        Read a CSV file from a given path and return a Pandas DataFrame\n",
    "        :param path: path to csv file\n",
    "        :return: returns Pandas DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def missing_percentage(df_insurance_train, other_dict = {}):\n",
    "        '''\n",
    "        input is a dataframe\n",
    "        \n",
    "        returns : the percentage of missing values\n",
    "        '''\n",
    "        \n",
    "        missing_df = df_insurance_train.isnull().sum().reset_index()\n",
    "        missing_df[\"total\"] = len(df_insurance_train)\n",
    "        missing_df.columns = [\"features\", \"null_count\", \"total\"]\n",
    "        missing_df[\"missing_percent\"] = round(missing_df[\"null_count\"]/missing_df.total*100, 2)\n",
    "        missing_df.sort_values(\"missing_percent\", ascending = False, inplace = True)\n",
    "\n",
    "        print(missing_df.to_markdown())\n",
    "        return missing_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def null_to_missing_cat(df_insurance_train, other_dict = {}):\n",
    "        '''\n",
    "        Input data frame with np.nan values and pandas NULL\n",
    "        \n",
    "        fillna() misses out np.nan\n",
    "        NAN and NONE are interchangable in pandas\n",
    "        \n",
    "        All null values are convereted to a class called missing_value\n",
    "        Output : pandas df with same shape\n",
    "        '''\n",
    "        \n",
    "        df = dict(df_insurance_train.dtypes)\n",
    "        hist_cols = [key for key in df.keys() if (df[key] == \"int64\" or df[key] == \"float64\")]\n",
    "\n",
    "        a = list(df_insurance_train.columns)\n",
    "        b = hist_cols\n",
    "        categorical_columns = list(set(a)-set(b))\n",
    "        \n",
    "        df_numeric = df_insurance_train[hist_cols]\n",
    "        \n",
    "        ## replace null values\n",
    "        df_insurance_train[categorical_columns].fillna('missing_value', inplace=True)\n",
    "        df_categorical = df_insurance_train[categorical_columns].replace(np.nan, 'missing_value', regex=True) # All data frame\n",
    "        \n",
    "        df_insurance_train =  pd.concat([df_categorical.reset_index(drop=True), df_numeric], axis=1)\n",
    "\n",
    "        DataClean.missing_percentage(df_insurance_train)\n",
    "        \n",
    "        return(df_insurance_train)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_col_mean_impute(df_insurance_train, num_impute_dict, other_dict = {}):\n",
    "        '''\n",
    "        inputs:\n",
    "        df_insurance_train - train dataframe with \n",
    "        num_impute_dict - \n",
    "        num_impute_dict = {\"Property Age\" : [\"Profession\", \"mean\"], \"Income (USD)\":[\"Profession\",  \"mean\"],\\\n",
    "                   \"Dependents\":[\"\", \"mode\"] , \"Credit Score\":[\"Has Active Credit Card\", \"mean\"],\\\n",
    "                  \"Loan Sanction Amount (USD)\":[\"\", 0], \"Current Loan Expenses (USD)\":[\"Profession\", \"mean\"]}\n",
    "        \n",
    "        The idea is to DO MORE, rn doing the minimum,\n",
    "        {\"Property Age\" : [\"Profession\", \"mean\"]} - The idea is, impute proterty age with mean property age of profession columns. \n",
    "        Business ideas, same profession guys look for similar property age. \n",
    "        A godown guy will look for older buildings, but a technie will look for new homes. \n",
    "        '''\n",
    "        impute_df = pd.DataFrame(num_impute_dict)\n",
    "        \n",
    "        ## helps to pretty print in jupyter we use to_markdown()\n",
    "        print(num_impute_dict)\n",
    "#         print(impute_df)\n",
    "        ## loop over the df\n",
    "        for cols in impute_df.columns:\n",
    "            print(cols)\n",
    "            x = impute_df[[cols]]\n",
    "#             print(x.columns[0]) \n",
    "            ## fillna with column mean.\n",
    "            df_insurance_train[cols].fillna(value= df_insurance_train[cols].mean(), inplace=True)\n",
    "        \n",
    "        DataClean.missing_percentage(df_insurance_train)\n",
    "        return df_insurance_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDataClean:\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_eng_vol(df_price_train):\n",
    "        '''\n",
    "        input df\n",
    "        output df\n",
    "        \n",
    "        1. split engine volume and make engine volume columns float. \n",
    "        2. in the new column turbo_flag_n, replace None with cat. \n",
    "        3. Remove outliers capped at 0 and 10 lower and upper bound\n",
    "        '''\n",
    "        print(df_price_train.shape)\n",
    "        a = df_price_train.shape\n",
    "        df_price_train[['Engine volume','turbo_flag_n']] = df_price_train['Engine volume'].str.split(' ',expand=True)\n",
    "        df_price_train['turbo_flag_n'].fillna(\"non_turbo\", inplace = True)\n",
    "        df_price_train[\"Engine volume\"] = df_price_train[\"Engine volume\"].astype(float)\n",
    "        \n",
    "        df_price_train[\"Engine volume\"] = np.where(df_price_train[\"Engine volume\"] <= 0 , 0, df_price_train[\"Engine volume\"])\n",
    "        df_price_train[\"Engine volume\"] = np.where(df_price_train[\"Engine volume\"] > 10 , 10, df_price_train[\"Engine volume\"])\n",
    "        \n",
    "        ## this threshold resulted in missing data points from test set, so clipping the values. \n",
    "#         df_price_train = df_price_train[(df_price_train[\"Engine volume\"] > 0)]\n",
    "#         df_price_train = df_price_train[(df_price_train[\"Engine volume\"] < 10)]\n",
    "        \n",
    "        print(df_price_train.shape)\n",
    "#         print(a- df_price_train.shape)\n",
    "        \n",
    "        return df_price_train\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_mileage(df_price_train):\n",
    "        '''\n",
    "        input and output are df\n",
    "        \n",
    "        1. convert mileage to continuous \n",
    "        2. replace 0 mileage with average mileage of a year- based on EDA. \n",
    "        3. Capping upper limit based on \n",
    "        (df_price_train[(df_price_train[\"Mileage\"]<=400000) & (df_price_train[\"Mileage\"] > 0)].Mileage).hist(bins = 100)\n",
    "        4. remove less than equal to 0 mileage\n",
    "        \n",
    "        '''\n",
    "        print(df_price_train.shape)\n",
    "        a = df_price_train.shape\n",
    "        df_price_train[\"Mileage\"] = df_price_train[\"Mileage\"].str.replace(\"km\", \"\")\n",
    "        df_price_train[\"Mileage\"] = df_price_train[\"Mileage\"].astype(int)\n",
    "        \n",
    "        ## replace 0 mileage with average year mileage - there is some patterm here. \n",
    "        avg_df = df_price_train.groupby([\"Prod. year\", \"Manufacturer\", \"Category\"]).agg({\"Mileage\":np.mean}).reset_index()\n",
    "        avg_df.columns = [\"Prod. year\", \"Manufacturer\", \"Category\", \"Mileage_avg\"]\n",
    "        new_df = df_price_train.merge(avg_df, how='left', on = [\"Prod. year\", \"Manufacturer\", \"Category\"])\n",
    "        \n",
    "        new_df.Mileage = np.where(new_df.Mileage == 0 , new_df.Mileage_avg, new_df.Mileage)\n",
    "        \n",
    "#         ## upper limit cap    \n",
    "        new_df.Mileage = np.where(new_df.Mileage > 300000 , 300000, new_df.Mileage)\n",
    "        \n",
    "        ## remove less than equal to 0\n",
    "        new_df.Mileage = np.where(new_df.Mileage <= 0 , 0, new_df.Mileage)\n",
    "        \n",
    "        ## resulted in loss of 300 data points from test so removed.\n",
    "#         new_df = new_df[new_df[\"Mileage\"] > 0 ]\n",
    "        \n",
    "        print(new_df.shape)\n",
    "#         print(a- df_price_train.shape)\n",
    "        return new_df\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_levy(df_price_train):\n",
    "        '''\n",
    "        input and output are df\n",
    "        \n",
    "        1. convert mileage to continuous \n",
    "\n",
    "        \n",
    "        '''\n",
    "        print(df_price_train.shape)\n",
    " \n",
    "        df_price_train.Levy  = np.where(df_price_train.Levy == \"-\", \"0\", df_price_train.Levy)\n",
    "        df_price_train.Levy = df_price_train[\"Levy\"].astype(int)\n",
    "        \n",
    "        ## replace 0 mileage with average year mileage - there is some patterm here. \n",
    "        avg_df = df_price_train.groupby([\"Prod. year\", \"Manufacturer\", \"Category\"]).agg({\"Levy\":np.mean}).reset_index()\n",
    "        avg_df.columns = [\"Prod. year\", \"Manufacturer\", \"Category\", \"Levy_avg\"]\n",
    "        new_df = df_price_train.merge(avg_df, how='left', on = [\"Prod. year\", \"Manufacturer\", \"Category\"])\n",
    "        \n",
    "        new_df.Levy = np.where(new_df.Levy == 0 , new_df.Levy_avg, new_df.Levy)\n",
    "        \n",
    "#         ## upper limit cap    \n",
    "#         new_df.Mileage = np.where(new_df.Mileage > 400000 , 400000, new_df.Mileage)\n",
    "        \n",
    "#         ## remove less than equal to 0\n",
    "#         new_df.Mileage = np.where(new_df.Mileage < 0 , 0, new_df.Mileage)\n",
    "        \n",
    "        ## resulted in loss of 300 data points from test so removed.\n",
    "#         new_df = new_df[new_df[\"Mileage\"] > 0 ]\n",
    "        \n",
    "        print(new_df.shape)\n",
    "#         print(a- df_price_train.shape)\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

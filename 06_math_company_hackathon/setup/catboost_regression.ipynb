{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catboost Regression Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.26-cp38-none-win_amd64.whl (68.4 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from catboost) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from catboost) (1.19.2)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from catboost) (1.5.2)\n",
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\chris.dmello\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11434 sha256=1aef1556e32127bc0d1a2cb334272641169bd5fd9ccd2af687a28640334d158c\n",
      "  Stored in directory: c:\\users\\chris.dmello\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: graphviz, retrying, plotly, catboost\n",
      "Successfully installed catboost-0.26 graphviz-0.16 plotly-4.14.3 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class catboost_regressor():\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, param = {}):\n",
    "        '''\n",
    "        '''\n",
    "        \n",
    "        self._rfr = CatBoostRegressor(**params) ## kwargs  loss_function='RMSE', iterations = 100\n",
    "        self._param = param\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def new_instance(cls, param={}):\n",
    "        '''\n",
    "        \n",
    "        rf_model_best = RF_regressor.new_instance(model_cv.best_params_)\n",
    "        \n",
    "        requires none, but if params is passed, it will call the init call and pass params to it,\n",
    "        '''\n",
    "        return cls(param)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Getter to return the model created\n",
    "        :return: handle or instance of the RandomForestReqgressor\n",
    "        \n",
    "        Property you can use it as a PARAM\n",
    "        as in rf_model.model will return the model.\n",
    "        \"\"\"\n",
    "        return self._rfr\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"\n",
    "        Getter for model parameters \n",
    "        \"\"\"\n",
    "        return self._param\n",
    "    \n",
    "    def model_run(self, df, var_dict,cat_features = {}, other_dict = {}):\n",
    "        '''\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        \n",
    "#         self._rfr  = self._rfr(cat_features) \n",
    "## TypeError: 'CatBoostRegressor' object is not callable\n",
    "\n",
    "        \n",
    "        self._rfr.fit(X_train, y_train)\n",
    "        y_pred = self._rfr.predict(X_test)\n",
    "        \n",
    "        model_score = self._rfr.score(X_test , y_test)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        msle = metrics.mean_squared_log_error(y_test, y_pred)\n",
    "        rmsle = np.sqrt(msle)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"msle\"] = msle\n",
    "        return_dict[\"rmsle\"] = rmsle\n",
    "        return_dict[\"model\"] = self.model\n",
    "        \n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "        return_dict[\"model_score\"] = model_score  ## here it is R2\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    def model_run_log(self, df, var_dict,cat_features = {}, other_dict = {}):\n",
    "        '''\n",
    "        We consider the log od predictions\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        \n",
    "        ## log of predictions\n",
    "        df[label] = np.log(df[label]+1)\n",
    "        \n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        \n",
    "#         self._rfr  = self._rfr(cat_features) \n",
    "## TypeError: 'CatBoostRegressor' object is not callable\n",
    "\n",
    "        \n",
    "        self._rfr.fit(X_train, y_train)\n",
    "        y_pred = self._rfr.predict(X_test)\n",
    "        \n",
    "        #y_pred = np.exp(y_pred_log)\n",
    "        \n",
    "        model_score = self._rfr.score(X_test , y_test)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        \n",
    "        msle = metrics.mean_squared_log_error(y_test, y_pred)\n",
    "        rmsle = np.sqrt(msle)\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"msle\"] = msle\n",
    "        return_dict[\"rmsle\"] = rmsle\n",
    "        return_dict[\"model\"] = self.model\n",
    "        \n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "        return_dict[\"model_score\"] = model_score  ## here it is R2\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    def model_run_log_complete(self, df, var_dict,cat_features = {}, other_dict = {}):\n",
    "        '''\n",
    "        When we do test train split, we loose some part of the data to test, we could use K-fold to counter this, or \n",
    "        Train the model on all of the test data. And no train data\n",
    "        \n",
    "        We consider the log od predictions\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        \n",
    "        ## log of predictions\n",
    "        df[label] = np.log(df[label]+1)\n",
    "        \n",
    "        X_train = df[feature]\n",
    "        y_train = df[label]\n",
    "        \n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        \n",
    "#         self._rfr  = self._rfr(cat_features) \n",
    "## TypeError: 'CatBoostRegressor' object is not callable\n",
    "\n",
    "        \n",
    "        self._rfr.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        y_pred = self._rfr.predict(X_train)\n",
    "        \n",
    "        #y_pred = np.exp(y_pred_log)\n",
    "        \n",
    "        model_score = self._rfr.score(X_train, y_train)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_train, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_train, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_train, y_pred)\n",
    "        \n",
    "        msle = metrics.mean_squared_log_error(y_train, y_pred)\n",
    "        rmsle = np.sqrt(msle)\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"msle\"] = msle\n",
    "        return_dict[\"rmsle\"] = rmsle\n",
    "        return_dict[\"model\"] = self.model\n",
    "        \n",
    "#         return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "        return_dict[\"model_score\"] = model_score  ## here it is R2\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    def model_run_cv(self, df, var_dict, other_dict = {}):\n",
    "        '''\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default - other_dict[\"parameters\"], other_dict[\"scoring\"], \n",
    "        other_dict[\"cv\"]\n",
    "        \n",
    "        neg_mean_absolute_error - we have to minimize mae, but sklearn works rf on maximization so we negative this\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        ## this has to be 2*2 matrix\n",
    "        \n",
    "#         self._rfr.fit(X_train, y_train)\n",
    "#         y_pred = self._rfr.predict(X_test)\n",
    "        \n",
    "    \n",
    "        param_grid = other_dict[\"parameters\"]\n",
    "        \n",
    "        # Instantiate the grid search model\n",
    "        grid_search_ad = GridSearchCV(  estimator = self._rfr, \n",
    "                                        param_grid = param_grid, \n",
    "                                        scoring = other_dict[\"scoring\"],  ## scoring method\n",
    "                                        cv = other_dict[\"cv\"],    ## no of cross validation\n",
    "                                        n_jobs = -1,    ## no of searches in parallel,-1 means, use all resources\n",
    "                                        verbose = 100)\n",
    "\n",
    "        grid_search_ad.fit(X_train, y_train)\n",
    "        y_pred = grid_search_ad.predict(X_test)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        \n",
    "        r2_2 = grid_search_ad.score(X_test, y_test)  ##score method of CV Features, Labels\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "          ## grid search CV doesnt have this\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"model_score\"] = r2_2\n",
    "        return_dict[\"model\"] = grid_search_ad\n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    \n",
    "    def model_run_cv_log(self, df, var_dict, other_dict = {}):\n",
    "        '''\n",
    "        self : rf catboost model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default - other_dict[\"parameters\"], other_dict[\"scoring\"], \n",
    "        other_dict[\"cv\"]\n",
    "        \n",
    "        neg_mean_absolute_error - we have to minimize mae, but sklearn works rf on maximization so we negative this\n",
    "        \n",
    "        ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
    "        \n",
    "        ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
    "\n",
    "        CatBoostError: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/target/\n",
    "        target_converter.cpp:53: NaN values are not supported for target\n",
    "\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        \n",
    "        ## natural log\n",
    "        df[label] = np.log(df[label] +1)\n",
    "        \n",
    "        print(df.isnull().any())\n",
    "        \n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        ## this has to be 2*2 matrix\n",
    "        \n",
    "#         self._rfr.fit(X_train, y_train)\n",
    "#         y_pred = self._rfr.predict(X_test)\n",
    "\n",
    "        \n",
    "        # Instantiate the grid search model\n",
    "        grid_search_ad = GridSearchCV(  estimator  = self._rfr, \n",
    "                                        param_grid = other_dict[\"param_grid\"], \n",
    "                                        scoring    = other_dict[\"scoring\"],  ## scoring method\n",
    "                                        cv         = other_dict[\"cv\"],    ## no of cross validation\n",
    "                                        n_jobs  = -1,    ## no of searches in parallel,-1 means, use all resources\n",
    "                                        verbose = 0)\n",
    "\n",
    "        \n",
    "        grid_search_ad.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = grid_search_ad.predict(X_test)\n",
    "        \n",
    "        mae   = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse   = metrics.mean_squared_error(y_test, y_pred)\n",
    "        msle  = metrics.mean_squared_log_error(y_test, y_pred)\n",
    "        rmsle = np.sqrt(msle)\n",
    "        rmse  = np.sqrt(mse)\n",
    "        r2    = metrics.r2_score(y_test, y_pred)\n",
    "        r2_2  = grid_search_ad.score(X_test, y_test)  ##score method of CV Features, Labels\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "          ## grid search CV doesnt have this\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"grid_search_ad.score\"] = r2_2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"msle\"] = msle\n",
    "        return_dict[\"rmsle\"] = rmsle\n",
    "        return_dict[\"model_score\"] = r2_2\n",
    "        return_dict[\"model\"] = grid_search_ad\n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def feature_importance(model, independant_col_list):\n",
    "        '''\n",
    "        input :\n",
    "        cat_model_base_005 - catboost model \n",
    "        independant_col_list - list of independant columns\n",
    "        '''\n",
    "        \n",
    "        fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': \\\n",
    "                                independant_col_list})\n",
    "        fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n",
    "        fea_imp.plot(kind='barh', x='col', y='imp', figsize=(10, 7), legend=None)\n",
    "        plt.title('CatBoost - Feature Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.xlabel('Importance');\n",
    "\n",
    "    \n",
    "#----------------------------------------- MLFLOW ----------------------------------------------------------#    \n",
    "    def model_run_mlfow(self, df, var_dict, other_dict = {}):\n",
    "        '''\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        \n",
    "        self._rfr.fit(X_train, y_train)\n",
    "        y_pred = self._rfr.predict(X_test)\n",
    "        \n",
    "        model_score = self._rfr.score(X_test , y_test)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "        bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"model\"] = self.model\n",
    "        \n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "        return_dict[\"model_score\"] = model_score  ## here it is R2\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    def model_run__log_mlfow(self, df, var_dict, other_dict = {}):\n",
    "        '''\n",
    "        self : rf regressor model\n",
    "        df   : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default\n",
    "        '''\n",
    "        \n",
    "        r_name = other_dict[\"run_name\"] \n",
    "        with mlflow.start_run(run_name=r_name) as run:\n",
    "\n",
    "            # get current run and experiment id\n",
    "            runID = run.info.run_uuid\n",
    "            experimentID = run.info.experiment_id\n",
    "\n",
    "            feature = var_dict[\"independant\"]\n",
    "            label   = var_dict[\"dependant\"]\n",
    "\n",
    "            ## log of predictions\n",
    "            df[label] = np.log(df[label]+1)\n",
    "\n",
    "            X = df[feature]\n",
    "            y = df[label]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "\n",
    "            self._rfr.fit(X_train, y_train)\n",
    "            y_pred = self._rfr.predict(X_test)\n",
    "            \n",
    "            ## self.model is a getter for the model\n",
    "            mlflow.sklearn.log_model(self.model, \"catboost-reg-model\")\n",
    "            mlflow.log_params(self.params)\n",
    "\n",
    "            model_score = self._rfr.score(X_test , y_test)\n",
    "\n",
    "            mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "            mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = metrics.r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    #         errors = abs(y_pred - y_test)\n",
    "    #         mape = 100 * np.mean(errors / y_test)\n",
    "    #         accuracy = 100 - mape\n",
    "\n",
    "#             bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "\n",
    "            return_dict = {}\n",
    "            return_dict[\"mae\"] = mae\n",
    "            return_dict[\"mse\"] = mse\n",
    "            return_dict[\"rmse\"] = rmse\n",
    "            return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "            return_dict[\"model\"] = self.model\n",
    "\n",
    "            return_dict[\"y_test\"] = y_test\n",
    "            return_dict[\"y_pred\"] = y_pred\n",
    "\n",
    "            return_dict[\"model_score\"] = model_score  ## here it is R2\n",
    "\n",
    "    #         return_dict[\"mape\"] = mape\n",
    "    #         return_dict[\"accuracy\"] = accuracy\n",
    "\n",
    "            ## TODO when model has no param\n",
    "    #         return_dict[\"param\"] = self.params  \n",
    "            \n",
    "            print(\"-\" * 100)\n",
    "            print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))\n",
    "#             print(\"Estimator trees        :\", self.params[\"n_estimators\"])\n",
    "            print('Mean Absolute Error    :', mae)\n",
    "            print('Mean Squared Error     :', mse)\n",
    "            print('Root Mean Squared Error:', rmse)\n",
    "            print('R2                     :', r2)\n",
    "\n",
    "            return (experimentID, runID)\n",
    "    \n",
    "    def model_run_cv_mlfow(self, df, var_dict, other_dict = {}):\n",
    "        '''\n",
    "        self : rf regressor model\n",
    "        df : dataframe\n",
    "        var_dict : model variables dict - var_dict[\"independant\"], var_dict[\"dependant\"]\n",
    "        other_dict : other dict if needed, set to {} default - other_dict[\"parameters\"], other_dict[\"scoring\"], \n",
    "        other_dict[\"cv\"]\n",
    "        \n",
    "        neg_mean_absolute_error - we have to minimize mae, but sklearn works rf on maximization so we negative this\n",
    "        '''\n",
    "        \n",
    "        feature = var_dict[\"independant\"]\n",
    "        label   = var_dict[\"dependant\"]\n",
    "        X = df[feature]\n",
    "        y = df[label]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 42)\n",
    "        ## this has to be 2*2 matrix\n",
    "        \n",
    "#         self._rfr.fit(X_train, y_train)\n",
    "#         y_pred = self._rfr.predict(X_test)\n",
    "        \n",
    "    \n",
    "        param_grid = other_dict[\"parameters\"]\n",
    "        \n",
    "        # Instantiate the grid search model\n",
    "        grid_search_ad = GridSearchCV(estimator = self._rfr, param_grid = param_grid, \n",
    "                                   scoring = other_dict[\"scoring\"], cv = other_dict[\"cv\"],  \n",
    "                                   n_jobs = -1, verbose = 2)\n",
    "\n",
    "        grid_search_ad.fit(X_train, y_train)\n",
    "        y_pred = grid_search_ad.predict(X_test)\n",
    "        \n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        \n",
    "        r2_2 = grid_search_ad.score(X_test, y_test)  ##score method of CV Features, Labels\n",
    "        \n",
    "#         errors = abs(y_pred - y_test)\n",
    "#         mape = 100 * np.mean(errors / y_test)\n",
    "#         accuracy = 100 - mape\n",
    "        \n",
    "#         bs = self.model.oob_score_  ## OOB score is same as R2, or co-eff of determination\n",
    "          ## grid search CV doesnt have this\n",
    "        \n",
    "        return_dict = {}\n",
    "        return_dict[\"mae\"] = mae\n",
    "        return_dict[\"mse\"] = mse\n",
    "        return_dict[\"rmse\"] = rmse\n",
    "        return_dict[\"r2\"] = r2   ## rf_model.score(test, pred) is same as r2\n",
    "        return_dict[\"model_score\"] = r2_2\n",
    "        return_dict[\"model\"] = grid_search_ad\n",
    "        return_dict[\"y_test\"] = y_test\n",
    "        return_dict[\"y_pred\"] = y_pred\n",
    "        \n",
    "#         return_dict[\"mape\"] = mape\n",
    "#         return_dict[\"accuracy\"] = accuracy\n",
    "        \n",
    "        ## TODO when model has no param\n",
    "#         return_dict[\"param\"] = self.params  \n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "\n",
    "    def train_with_all_data():\n",
    "        '''\n",
    "        Once we find th best model, train with all data \n",
    "        '''\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
